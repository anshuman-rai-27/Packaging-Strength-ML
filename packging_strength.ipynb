{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL5cGtpiIaWs",
        "outputId": "4626f837-74c5-420d-bc2d-19e8c5e88b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7184085\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Heavy       0.75      0.84      0.80    808380\n",
            "       Light       0.78      0.48      0.60    338703\n",
            "      Medium       0.67      0.69      0.68    852917\n",
            "\n",
            "    accuracy                           0.72   2000000\n",
            "   macro avg       0.73      0.67      0.69   2000000\n",
            "weighted avg       0.72      0.72      0.71   2000000\n",
            "\n",
            "Model pipeline and label encoder saved.\n",
            "[{'layer': 0, 'suggested_strength': 'Medium'}, {'layer': 1, 'suggested_strength': 'Medium'}]\n"
          ]
        }
      ],
      "source": [
        "# Google Colab Notebook: Packaging Strength Recommendation per Layer\n",
        "\n",
        "# ----------------------------------------\n",
        "# Cell 1: Install Dependencies\n",
        "# ----------------------------------------\n",
        "!pip install --quiet pandas numpy scikit-learn xgboost matplotlib\n",
        "\n",
        "# ----------------------------------------\n",
        "# Cell 2: Imports\n",
        "# ----------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "\n",
        "# ----------------------------------------\n",
        "# Cell 3: Synthetic Data Generation\n",
        "# ----------------------------------------\n",
        "def generate_synthetic_data(n_samples=10000000, n_layers=4, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    rows = []\n",
        "    # Map for ECT\n",
        "    ECT_map = {'corrugated': 3, 'plastic': 2, 'wood': 4}\n",
        "    for _ in range(n_samples):\n",
        "        layer = np.random.randint(0, n_layers)\n",
        "        num_boxes = np.random.randint(5, 20)\n",
        "        avg_box_weight = np.random.uniform(2, 20)  # kg\n",
        "        total_weight_above = layer * num_boxes * avg_box_weight\n",
        "        box_material = np.random.choice(list(ECT_map.keys()))\n",
        "        box_thickness = np.random.uniform(1, 10)  # mm\n",
        "        fragile = np.random.choice([0, 1], p=[0.8, 0.2])\n",
        "        perimeter = num_boxes * box_thickness\n",
        "        depth = np.random.uniform(10, 100)\n",
        "        k = 5.87\n",
        "        C = k * ECT_map[box_material] * np.sqrt(perimeter * depth)\n",
        "        # Bin C into strength levels\n",
        "        if C < 500:\n",
        "            strength = 'Light'\n",
        "        elif C < 1000:\n",
        "            strength = 'Medium'\n",
        "        else:\n",
        "            strength = 'Heavy'\n",
        "        rows.append({\n",
        "            'layer': layer,\n",
        "            'num_boxes': num_boxes,\n",
        "            'avg_box_weight': avg_box_weight,\n",
        "            'total_weight_above': total_weight_above,\n",
        "            'box_material': box_material,\n",
        "            'box_thickness': box_thickness,\n",
        "            'fragile': fragile,\n",
        "            'strength': strength\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# Generate data\n",
        "df = generate_synthetic_data()\n",
        "df.head()\n",
        "\n",
        "# ----------------------------------------\n",
        "# Cell 4: Preprocessing & Feature Pipeline\n",
        "# ----------------------------------------\n",
        "# Features and target\n",
        "X = df.drop('strength', axis=1)\n",
        "y = df['strength']\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # Light=1, Medium=2, Heavy=0 (example)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Preprocessing for features\n",
        "numeric_features = ['layer', 'num_boxes', 'avg_box_weight', 'total_weight_above', 'box_thickness']\n",
        "categorical_features = ['box_material', 'fragile']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', cat_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ----------------------------------------\n",
        "# Cell 5: Model Pipeline & Training\n",
        "# ----------------------------------------\n",
        "model = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=3,\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', model)\n",
        "])\n",
        "\n",
        "# Train model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# ----------------------------------------\n",
        "# Cell 6: Evaluation\n",
        "# ----------------------------------------\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Decode labels for readability\n",
        "y_test_labels = label_encoder.inverse_transform(y_test)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "# Metrics\n",
        "print(\"Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_labels, y_pred_labels))\n",
        "\n",
        "# ----------------------------------------\n",
        "# Cell 7: Save Model and Label Encoder\n",
        "# ----------------------------------------\n",
        "with open('packaging_strength_model.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f)\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(\"Model pipeline and label encoder saved.\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# Cell 8: Prediction Function\n",
        "# ----------------------------------------\n",
        "def recommend_strength_for_layers(layer_data, model_path='packaging_strength_model.pkl', le_path='label_encoder.pkl'):\n",
        "    \"\"\"\n",
        "    layer_data: List of dicts, each with keys:\n",
        "      layer, num_boxes, avg_box_weight, total_weight_above,\n",
        "      box_material, box_thickness, fragile\n",
        "    \"\"\"\n",
        "    df_layers = pd.DataFrame(layer_data)\n",
        "    # Load model and encoder\n",
        "    with open(model_path, 'rb') as f:\n",
        "        pipeline = pickle.load(f)\n",
        "    with open(le_path, 'rb') as f:\n",
        "        le = pickle.load(f)\n",
        "    preds_encoded = pipeline.predict(df_layers)\n",
        "    preds = le.inverse_transform(preds_encoded)\n",
        "    return [{'layer': ld['layer'], 'suggested_strength': p}\n",
        "            for ld, p in zip(layer_data, preds)]\n",
        "\n",
        "# Example usage\n",
        "example = [\n",
        "    {'layer': 0, 'num_boxes': 10, 'avg_box_weight': 5.0, 'total_weight_above': 0,\n",
        "     'box_material': 'corrugated', 'box_thickness': 5, 'fragile': 0},\n",
        "    {'layer': 1, 'num_boxes': 10, 'avg_box_weight': 5.0, 'total_weight_above': 50,\n",
        "     'box_material': 'corrugated', 'box_thickness': 5, 'fragile': 0}\n",
        "]\n",
        "print(recommend_strength_for_layers(example))\n",
        "\n",
        "# ----------------------------------------\n",
        "# Cell 9: Next Steps & Hyperparameter Tuning\n",
        "# ----------------------------------------\n",
        "# - Use GridSearchCV or Optuna to tune hyperparameters.\n",
        "# - Replace synthetic data with real test data or sensor logs.\n",
        "# - Integrate into FastAPI or Streamlit for vendor interface.\n"
      ]
    }
  ]
}